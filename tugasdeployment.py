# -*- coding: utf-8 -*-
"""tugasDeployment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/103XZtY_KfshrzKaU4QhuUNJ-Gg1FrXD-

####**nama : Wira triono**

####**kota : Pematangsiantar(Sumatra utara)**
---
# **Prediksi Nama Buah**
---
> project submission saya yaitu memprediksi nama 4 macam buah yaitu **apel, jeruk, mangga dan pisang**. total jumlah datasets ada **>10000 sample** yg dari 4 kategori itu **masing-masing memiliki >2500 sample**. **Resolusi gambar** yang ada di dataset saya **beragam** karna saya mendapatkannya dari sumber yang berbeda beda. Data diupload ke Gdrive dalam bentik **zip file**
---
sumber gambar:
*   https://www.kaggle.com/datasets (kaggle)
*   https://storage.googleapis.com/openimages/web/index.html (Open Images V6)
*   https://www.bing.com/images (bing)

#download dan extract dataset
"""

! gdown 1rf7DPzh58X234HVI5lXU4TrLBu7d-8p-

# unzip file
! unzip -q ImgDataset.zip

# install splitfolder
!pip install split-folders

# import modul
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
import tensorflow as tf
import matplotlib.pyplot as plt
import splitfolders
import pathlib
import os

"""#menampilkan gambar """

images = image_dataset_from_directory("/content/ImgDataset/gambar",
                                      shuffle=True)

nama_label = images.class_names

plt.figure(figsize=(10,10))
for img, label in images.take(1):
  for i in range(9):
    ax = plt.subplot(3,3,i+1)
    plt.imshow(img[i].numpy().astype("uint8"))
    plt.title(nama_label[label[i]])
    plt.axis('off')

"""#split data menjadi train(80%) dan tes(20%)"""

path_img = "/content/ImgDataset/gambar"
path_output = "/content/ImgDataset"

splitfolders.ratio(path_img, path_output, seed=1337, ratio=(0.8,0.2), group_prefix=None)

train_dir = os.path.join(path_output,"train")
val_dir = os.path.join(path_output,"val")

"""#Augmentasi data"""

img_shape = (224,224)

# train
train_gen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=30,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    zoom_range = 0.1,
                    fill_mode = 'nearest')

train = train_gen.flow_from_directory(
                    train_dir,
                    batch_size=128,
                    target_size= img_shape,
                    class_mode = "categorical")
 

# test
test_gen = ImageDataGenerator(
                    rescale=1./255)

test = test_gen.flow_from_directory(
                    val_dir,
                    batch_size=128,
                    target_size= img_shape,
                    class_mode = "categorical")

"""#Transfer learning MobileNet"""

mobileNetv2 = MobileNetV2(input_shape=(img_shape+(3,)),
                        weights="imagenet",
                        include_top=False)

mobileNetv2.trainable = False

"""#Modelling"""

from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras import Sequential, optimizers, losses, callbacks, regularizers

class myCallback(callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if((logs.get('accuracy') - logs.get('val_accuracy')) > 0.01):
      print("\n Stop training")
      self.model.stop_training = True

callbacks = myCallback()

model = Sequential([
    mobileNetv2,
    Flatten(),
    Dropout(0.2),
    Dense(64, activation='swish', kernel_regularizer= regularizers.L1(0.001)),
    Dropout(0.2),
    Dense(64, activation='swish', kernel_regularizer= regularizers.L1(0.001)),
    Dense(4, activation='softmax')
])


model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),
              loss=losses.CategoricalCrossentropy(),
              metrics=['accuracy'])

model.summary()

hist = model.fit(train,
          epochs=10,
          steps_per_epoch=32,
          callbacks=callbacks,
          validation_data=test,
          validation_steps=10,
          verbose=1)

"""#Plot akurasi dan loss"""

acc= hist.history['accuracy']
val= hist.history['val_accuracy']
loss= hist.history["loss"]
valloss= hist.history["val_loss"]

fig,ax = plt.subplots(2,1,figsize=(8,6))
ax[0].plot(acc,'orange',label="train")
ax[0].plot(val,"blue",label="val")
ax[0].set_title("akurasi dan loss",fontsize=20)
ax[0].set_ylabel("akurasi",fontsize=15)
ax[0].legend()

ax[1].plot(loss,'orange',label="train")
ax[1].plot(valloss,"blue",label="val")
ax[1].set_ylabel("loss",fontsize=15)
ax[1].set_xlabel("epoch",fontsize=17)
ax[1].legend()
plt.show()

"""#save model dan convert ke tflite"""

export_dir = '/content/ImgDataset'
tf.saved_model.save(model, export_dir)

converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()

tflite_model_file = pathlib.Path('vegs.tflite')
tflite_model_file.write_bytes(tflite_model)